
const video = document.getElementById('camera');
const captureButton = document.getElementById('capture');
const snapshotCanvas = document.getElementById('snapshot');
const resultDiv = document.getElementById('result');
const fileUploadInput = document.getElementById('file-upload');
const cameraSection = document.getElementById('camera-section'); 
const previewImg = document.getElementById('uploaded-image-preview');

const MODEL_URL = 'plant_model_js/model.json'; 
const IMAGE_SIZE = 256; 

let model;

let classNames = window.CLASS_NAMES || []; 

async function loadModel() {
    resultDiv.textContent = '‚è≥ ƒêang t·∫£i m√¥ h√¨nh AI...';
    try {

        model = await tf.loadLayersModel(MODEL_URL);
        
        if (classNames.length === 0) {
             resultDiv.textContent = '‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y nh√£n CLASS_NAMES. Vui l√≤ng ki·ªÉm tra file labels.js.';
             return;
        }

        resultDiv.textContent = `‚úÖ M√¥ h√¨nh ƒë√£ s·∫µn s√†ng. (${classNames.length} lo·∫°i b·ªánh)`;
    } catch (err) {
      
        console.error("L·ªói khi t·∫£i m√¥ h√¨nh:", err);
        resultDiv.textContent = '‚ùå L·ªói khi t·∫£i m√¥ h√¨nh AI. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n ho·∫∑c file model.json.';
    }
}

async function runModelPrediction() {
    if (!model) {
        resultDiv.textContent = '‚ö†Ô∏è M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i. ƒêang t·∫£i l·∫°i...';
        await loadModel();
        if (!model) return;
    }
    
    resultDiv.textContent = 'üß† ƒêang ph√¢n t√≠ch h√¨nh ·∫£nh...';
    
  
    let tensor = tf.browser.fromPixels(snapshotCanvas)
        .resizeNearestNeighbor([IMAGE_SIZE, IMAGE_SIZE]) 
        .toFloat();

  
    tensor = tf.sub(tf.div(tensor, 127.5), 1);
    
    const expandedTensor = tensor.expandDims(0);
    
    const prediction = await model.predict(expandedTensor).data();
    
    const predictedClassIndex = prediction.indexOf(Math.max(...prediction));
    const predictedClass = classNames[predictedClassIndex] || 'Kh√¥ng x√°c ƒë·ªãnh';
    const confidence = prediction[predictedClassIndex] * 100;


    let resultText = `K·∫øt qu·∫£: **${predictedClass}**`;
    
    if (predictedClass.toLowerCase().includes('healthy')) {
        resultText = `**Ph√¢n lo·∫°i:** C√¢y kh·ªèe m·∫°nh üéâ (**${predictedClass}**)`;
    } else if (predictedClass !== 'Kh√¥ng x√°c ƒë·ªãnh') {
        resultText = `**Ph√¢n lo·∫°i:** C√¢y b·ªã b·ªánh! üö® (**${predictedClass}**)`;
    }
    
    resultDiv.innerHTML = `${resultText}<br>**ƒê·ªô tin c·∫≠y:** ${confidence.toFixed(2)}%`;

    // Gi·∫£i ph√≥ng b·ªô nh·ªõ Tensor
    tf.dispose([tensor, expandedTensor]);
}




async function startCamera() {
    
    await loadModel();

    try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        
    } catch (err) {
        console.error("L·ªói khi truy c·∫≠p camera:", err);
        resultDiv.textContent = '‚ùå Kh√¥ng th·ªÉ truy c·∫≠p camera. Vui l√≤ng ki·ªÉm tra quy·ªÅn.';
        video.style.display = 'none'; 
    }
}

captureButton.addEventListener('click', () => {
    if (video.srcObject) {
   
        snapshotCanvas.width = video.videoWidth;
        snapshotCanvas.height = video.videoHeight;
        const context = snapshotCanvas.getContext('2d');
        context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);        
        
        const imageDataURL = snapshotCanvas.toDataURL('image/jpeg');
        video.style.display = 'none';
        previewImg.src = imageDataURL;
        previewImg.style.display = 'block';

        resultDiv.textContent = 'üì∏ ·∫¢nh ƒë√£ ch·ª•p. ƒêang ph√¢n t√≠ch...';
        runModelPrediction();

    } else {
        resultDiv.textContent = '‚ö†Ô∏è Camera ch∆∞a s·∫µn s√†ng ho·∫∑c ƒë√£ b·ªã t·∫Øt.';
    }
});

fileUploadInput.addEventListener('change', (event) => {
    const file = event.target.files[0];
    if (file) {
        const reader = new FileReader();
        
        reader.onload = function(e) {
            video.style.display = 'none';
            previewImg.src = e.target.result;
            previewImg.style.display = 'block';
     
            const img = new Image();
            img.onload = function() {
                snapshotCanvas.width = img.width;
                snapshotCanvas.height = img.height;
                const context = snapshotCanvas.getContext('2d');
                context.drawImage(img, 0, 0);
                

                runModelPrediction();
            };
            img.src = e.target.result;

            resultDiv.textContent = `‚¨ÜÔ∏è ƒê√£ t·∫£i l√™n "${file.name}". ƒêang ph√¢n t√≠ch...`;
        };
        
        reader.readAsDataURL(file);
    }
});



window.onload = startCamera;
